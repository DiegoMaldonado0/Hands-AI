# MODEL - BRANCH
Traductor y lector con voz de lenguaje de señas en tiempo real utilizando visión artificial y Machine Learning para el reconocimiento de cada seña. Con un FrontEnd desarrollado en React y Vite.

![frame](https://github.com/user-attachments/assets/e834811a-777c-417b-9be4-83991d1ae3fb)

https://diegomaldonado0.github.io/Hands-AI/

# Explicación

El repositorio incluye todo el frontend con su conexión a nuestra API creada en FastApi que fue hosteada al final en Render para poder utilizarla en otras maneras que no sea local y poderle hacer un display al proyecto.

Para poder tener tu el repositorio es tan fácil como clonar este repo con el siguiente comando

```
npm clone https://github.com/DiegoMaldonado0/Hands-AI
```
Una vez teniendo todos los archivos si lo quieres correr de manera local, bastaría con correr los siguientes comandos : 
```
npm install
npm run dev
```
# Muestras del trabajo en tiempo real

Ahora así es como se ve el proyecto ya terminado:

![image](https://github.com/user-attachments/assets/5da2e52d-709e-422e-82b8-d90879f9df27)

![image](https://github.com/user-attachments/assets/d2d31bdd-6b3d-4788-958f-ec5dc88b8155)

![image](https://github.com/user-attachments/assets/c3fa4cce-d3ed-4522-82d6-e1098304b245)

![image](https://github.com/user-attachments/assets/19940bf7-00f4-48b6-ab4d-40f20dbd2b67)

![image](https://github.com/user-attachments/assets/46448975-de8a-4f0c-bbb3-a274ed92e869)

Para el tema de los usuarios decidimos concetar nuestro programa con FireBase y manejar la Authentication.

Y eso sería todo conectado y funcionando de manera correcta :)


