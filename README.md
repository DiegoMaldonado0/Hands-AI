# MODEL - BRANCH
Traductor y lector con voz de lenguaje de señas en tiempo real utilizando visión artificial y Machine Learning para el reconocimiento de cada seña. Con un FrontEnd desarrollado en React y Vite.

![frame](https://github.com/user-attachments/assets/e834811a-777c-417b-9be4-83991d1ae3fb)

https://diegomaldonado0.github.io/Hands-AI/

# Explicación

El repositorio incluye todo el frontend con su conexión a nuestra API creada en FastApi que fue hosteada al final en Render para poder utilizarla en otras maneras que no sea local y poderle hacer un display al proyecto.

Para poder tener tu el repositorio es tan fácil como clonar este repo con el siguiente comando

```
npm clone https://github.com/DiegoMaldonado0/Hands-AI
```
Una vez teniendo todos los archivos si lo quieres correr de manera local, bastaría con correr los siguientes comandos : 
```
npm install
npm run dev
```
# Muestras del trabajo en tiempo real

Ahora así es como se ve el proyecto ya terminado:

![image](https://github.com/user-attachments/assets/195ae3c5-59f3-408e-9c4d-d11b18c849b1)

![image](https://github.com/user-attachments/assets/4526a60a-2b96-4ec6-a3db-3f8f62871a5f)

![image](https://github.com/user-attachments/assets/86e18a2c-8497-4a2f-993b-87d8902e408d)

![image](https://github.com/user-attachments/assets/77206911-cfe1-4e35-a98e-11e1de2643d7)

![image](https://github.com/user-attachments/assets/0c04664f-5cdf-4cb7-bff5-bda178cfcdf7)

Para el tema de los usuarios decidimos concetar nuestro programa con FireBase y manejar la Authentication.

Y eso sería todo conectado y funcionando de manera correcta :)


